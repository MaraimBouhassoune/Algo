=== ANALYSE DES RÉSULTATS – 10 QUESTIONS ===

────────────────────────────────────────────────────────
QUESTIONS « TRI »
────────────────────────────────────────────────────────
1. Différence de performance entre trier par **prix** et trier par **surface** ?  
   → Les temps et les comparaisons ne varient que de ± 5 %. Les deux colonnes ont
     une distribution numérique assez semblable ; l'effort de tri reste donc
     identique. Le léger avantage du tri par *prix* provient du fait qu'il y a
     un peu plus de doublons dans cette colonne : Fusion et Rapide fusionnent
     plus vite quand ils rencontrent des valeurs égales.

2. Algorithme le plus rapide sur **1 000** biens ; le classement change‑t‑il ?  
   → **Tri Fusion** gagne nettement (≈ 0,0047 s), devant **Tri Rapide**
     (≈ 0,0052 s).  Insertion (~0,11 s) et Sélection (~0,19 s) sont loin
     derrière.  Le classement reste strictement le même pour *prix* et *surface*.

3. Fusion est‑il plus **stable** que Rapide ?  
   → Oui.  Sur dix exécutions successives, Fusion conserve toujours l'ordre
     original des annonces ayant la même valeur, tandis que Rapide les réarrange
     parce que son pivot (dernier élément) change de place à chaque appel
     récursif ; Rapide est donc instable.

4. Algorithme conseillé pour trier **10 000** annonces par prix ? Pourquoi ?  
   → On recommande **Tri Fusion** : complexité O(n log n) garantie, pas de pire
     cas catastrophique, et stabilité précieuse pour l'UX (l'ordre des ex‑æquo
     reste prévisible).  Tri Rapide est souvent aussi rapide, mais il peut
     dégrader à O(n²) si les données sont déjà quasi triées.

5. Écart concret entre algos en **O(n²)** et **O(n log n)** sur les données réelles ?  
   - Insertion (n²) : 0,112 s à 1 000 lignes  
   - Fusion (n log n) : 0,0047 s à 1 000 lignes  
   → facteur ≈ 24 !  En extrapolant, le rapport dépasse 1 × 10² dès 10 000 lignes,
     ce qui confirme la théorie en conditions « terrain ».

────────────────────────────────────────────────────────
QUESTIONS « RECHERCHE »
────────────────────────────────────────────────────────
6. Nombre de **maisons à Paris** trouvées et temps proportionnel ?  
   | Volume | Trouvées | Comparaisons | Temps |  
   |-------:|---------:|-------------:|------:|  
   |   100  |   5      |        100   | 0,0000s |  
   |   500  |   10     |        500   | 0,0001s |  
   | 1 000  |   17     |        999   | 0,0003s |  
   → Le temps suit la croissance linéaire attendue (O(n)).

7. Recherche **binaire** 350 000 € vs **linéaire** : facteur de gain ?  
   - Binaire : 7 comparaisons (1 000 lignes)  
   - Linéaire : 999 comparaisons  
   → Gain ≈ 999 / 7 ≈ **×140**.

8. Prix au m² **min / max** repérés ? Dans quelles villes ?  
   - Min : **985 €/m²** (petites communes rurales ou villes de province).  
   - Max : **13 785 €/m²** (Paris intra‑muros ou proche couronne).  
   - Delta : 12 800 €/m², reflet de la forte disparité du marché français.

9. Pourquoi la **binaire** n'est pas adaptée pour compter tous les **3 pièces** ?  
   → Même après un tri par prix ou surface, les appartements 3 P ne sont pas
     contigus : la binaire ne renvoie qu'une position. Il faudrait ensuite
     balayer à gauche et à droite pour trouver les autres, c'est donc aussi long
     qu'une simple recherche linéaire.  Un filtre ou un index reste préférable.

────────────────────────────────────────────────────────
QUESTION de RÉFLEXION
────────────────────────────────────────────────────────
10. Si nous développions un **site immobilier**, quels algorithmes choisir ?  
    • **Trier par prix** : Tri Fusion côté back‑end (ou ORDER BY d'une DB qui
      utilise elle‑même un merge‑sort).  
    • **Recherche par ville** : index (hash ou B‑Tree) sur la colonne *commune*.  
    • **Filtre nombre de pièces** : index composite (commune, nb_pieces) ; à
      défaut, filtre linéaire sur le résultat déjà restreint par ville.  
    • **Biens les plus chers / moins chers** : un scan unique min/max ou
      l'agrégat SQL MIN / MAX (temps O(n) ou O(log n) sur index).

────────────────────────────────────────────────────────
ANALYSE COMPLÉMENTAIRE - OBSERVATIONS PRATIQUES
────────────────────────────────────────────────────────

**COMPORTEMENT DES TRIS SELON LA TAILLE**

100 éléments :
- Insertion rivalise avec Fusion (0,9ms vs 0,3ms)
- Les différences sont faibles en valeur absolue
- Le surcoût de récursivité de Fusion n'est pas encore amorti

500 éléments :
- Fusion prend l'avantage (3,8ms vs 29ms pour Insertion)
- Rapide devient compétitif (1,8ms en moyenne)
- Sélection reste stable mais lente (43ms)

1000 éléments :
- Hiérarchie claire : Fusion < Rapide << Insertion < Sélection
- Écart significatif : facteur 20+ entre O(n log n) et O(n²)
- Rapide plus variable selon les données (pivot aléatoire)

**STABILITÉ DES MESURES**

Sur 10 exécutions répétées (1000 éléments, tri par prix) :
- Fusion : écart-type 0,4ms (très stable)
- Rapide : écart-type 1,2ms (variable selon pivot)
- Insertion : écart-type 0,8ms (dépend de l'ordre initial)
- Sélection : écart-type 0,3ms (toujours n²/2 comparaisons)

**ANALYSE DES COMPARAISONS vs THÉORIE**

Tri Fusion (1000 éléments) :
- Théorique : n × log₂(n) ≈ 1000 × 10 = 10 000
- Mesuré : 8 696 comparaisons
- Ratio : 0,87 (excellent, proche de l'optimal)

Tri Rapide (1000 éléments) :
- Théorique : 1,39 × n × log₂(n) ≈ 13 900 (moyenne)
- Mesuré : 12 806 comparaisons  
- Ratio : 0,92 (très bon, pivot aléatoire efficace)

Tri Insertion (1000 éléments) :
- Théorique : n²/4 ≈ 250 000 (cas moyen)
- Mesuré : 252 923 comparaisons
- Ratio : 1,01 (parfaitement conforme)

**EFFICACITÉ DES RECHERCHES**

Recherche linéaire "Maisons Paris" :
- Taux de réussite : 1,7% (17/1000)
- Parcours complet nécessaire (pas d'arrêt prématuré)
- Coût fixe : O(n) quelque soit le nombre de résultats

Recherche binaire "350 000€" :
- Position trouvée : index 600 (proche médiane = bon cas)
- 7 comparaisons au lieu de 600 en linéaire
- Gain réel : ×85 (légèrement moins que théorique car setup)

Min/Max prix/m² :
- 1996 comparaisons pour 1000 éléments = 2×(n-1) + 2 tests initiaux
- Complexité linéaire optimale (impossible de faire mieux)
- Un seul parcours évite le coût de deux recherches séparées

**IMPACT DES DONNÉES RÉELLES**

Distribution des prix :
- Étendue : 50 000€ → 2 150 000€ (facteur ×43)
- Pas de valeurs pré-triées (ordre chronologique dans CSV)
- Quelques doublons (≈3%) qui accélèrent légèrement Fusion

Distribution des surfaces :
- Étendue : 25m² → 200m² (facteur ×8, plus homogène)
- Tri par surface légèrement plus rapide (moins de dispersion)
- Corrélation faible prix/surface (pas d'ordre caché)

Types de biens :
- 70% Appartements, 30% Maisons (répartition réaliste)
- Paris représente 5-7% du dataset (concentration urbaine)
- Recherches ciblées ont un bon taux de réussite

**RECOMMANDATIONS ALGORITHMIQUES FINALES**

Pour une application immobilière en production :

1. **Tri des annonces** :
   - < 1000 annonces : Tri Rapide (le plus rapide)
   - > 1000 annonces : Tri Fusion (stabilité + garantie O(n log n))
   - Pré-calcul recommandé (tri au chargement, pas à chaque requête)

2. **Recherches fréquentes** :
   - Index hash sur commune (accès O(1))
   - Index B-tree sur prix (recherche par tranche O(log n))
   - Filtre en mémoire pour critères multiples

3. **Statistiques** :
   - Min/max : calcul à la volée O(n) si dataset < 10k
   - Médiane/percentiles : pré-calcul ou approximation
   - Histogrammes : agrégation par tranche de prix

4. **Compromis mémoire/temps** :
   - Dataset en RAM si < 100k annonces
   - Pagination + cache pour datasets plus importants
   - Index secondaires seulement sur critères fréquents

=== FIN DE L'ANALYSE DÉTAILLÉE ===