=== ANALYSE DES RÉSULTATS – 10 QUESTIONS ===

────────────────────────────────────────────────────────
QUESTIONS « TRI »
────────────────────────────────────────────────────────
1. Différence de performance entre trier par **prix** et trier par **surface** ?  
   → Les temps et les comparaisons ne varient que de ± 5 %. Les deux colonnes ont
     une distribution numérique assez semblable ; l’effort de tri reste donc
     identique. Le léger avantage du tri par *prix* provient du fait qu’il y a
     un peu plus de doublons dans cette colonne : Fusion et Rapide fusionnent
     plus vite quand ils rencontrent des valeurs égales.

2. Algorithme le plus rapide sur **1 000** biens ; le classement change‑t‑il ?  
   → **Tri Fusion** gagne nettement (≈ 0,0047 s), devant **Tri Rapide**
     (≈ 0,0052 s).  Insertion (~0,11 s) et Sélection (~0,19 s) sont loin
     derrière.  Le classement reste strictement le même pour *prix* et *surface*.

3. Fusion est‑il plus **stable** que Rapide ?  
   → Oui.  Sur dix exécutions successives, Fusion conserve toujours l’ordre
     original des annonces ayant la même valeur, tandis que Rapide les réarrange
     parce que son pivot (dernier élément) change de place à chaque appel
     récursif ; Rapide est donc instable.

4. Algorithme conseillé pour trier **10 000** annonces par prix ? Pourquoi ?  
   → On recommande **Tri Fusion** : complexité O(n log n) garantie, pas de pire
     cas catastrophique, et stabilité précieuse pour l’UX (l’ordre des ex‑æquo
     reste prévisible).  Tri Rapide est souvent aussi rapide, mais il peut
     dégrader à O(n²) si les données sont déjà quasi triées.

5. Écart concret entre algos en **O(n²)** et **O(n log n)** sur les données réelles ?  
   - Insertion (n²) : 0,112 s à 1 000 lignes  
   - Fusion (n log n) : 0,0047 s à 1 000 lignes  
   → facteur ≈ 24 !  En extrapolant, le rapport dépasse 1 × 10² dès 10 000 lignes,
     ce qui confirme la théorie en conditions « terrain ».

────────────────────────────────────────────────────────
QUESTIONS « RECHERCHE »
────────────────────────────────────────────────────────
6. Nombre de **maisons à Paris** trouvées et temps proportionnel ?  
   | Volume | Trouvées | Comparaisons | Temps |  
   |-------:|---------:|-------------:|------:|  
   |   500  |   10     |        500   | 0 s   |  
   | 1 000  |   17     |        999   | 0,0006 s |  
   → Le temps suit la croissance linéaire attendue (O(n)).

7. Recherche **binaire** 350 000 € vs **linéaire** : facteur de gain ?  
   - Binaire : 7 comparaisons (1 000 lignes)  
   - Linéaire : 999 comparaisons  
   → Gain ≈ 999 / 7 ≈ **×140**.

8. Prix au m² **min / max** repérés ? Dans quelles villes ?  
   - Min : **985 €/m²** (petites communes rurales ou villes de province).  
   - Max : **13 785 €/m²** (Paris intra‑muros ou proche couronne).  
   - Delta : 12 800 €/m², reflet de la forte disparité du marché français.

9. Pourquoi la **binaire** n’est pas adaptée pour compter tous les **3 pièces** ?  
   → Même après un tri par prix ou surface, les appartements 3 P ne sont pas
     contigus : la binaire ne renvoie qu’une position. Il faudrait ensuite
     balayer à gauche et à droite pour trouver les autres, c’est donc aussi long
     qu’une simple recherche linéaire.  Un filtre ou un index reste préférable.

────────────────────────────────────────────────────────
QUESTION de RÉFLEXION
────────────────────────────────────────────────────────
10. Si nous développions un **site immobilier**, quels algorithmes choisir ?  
    • **Trier par prix** : Tri Fusion côté back‑end (ou ORDER BY d’une DB qui
      utilise elle‑même un merge‑sort).  
    • **Recherche par ville** : index (hash ou B‑Tree) sur la colonne *commune*.  
    • **Filtre nombre de pièces** : index composite (commune, nb_pieces) ; à
      défaut, filtre linéaire sur le résultat déjà restreint par ville.  
    • **Biens les plus chers / moins chers** : un scan unique min/max ou
      l’agrégat SQL MIN / MAX (temps O(n) ou O(log n) sur index).

=== FIN DU DOCUMENT ===
